# Client bootstrapping
// API_VERSIONS, SASL*, METADATA

## Motivating questions

. How are clients both forwards and backwards compatible with brokers?
. How does a client discover and keep up to date with the current cluster state?

## Overview

When a client starts up it has no existing knowledge of the cluster state, it only has the set of "bootstrap servers" with which it has been configured.
Bootstrapping is the process of connecting to one of those servers and discovering the necessary cluster state in order to perform whatever that client is supposed to do. 
The necessary cluster state includes the available brokers and their addresses and possibly information about topics of interest.

In order to do this it needs:

1. To know how to talk to the bootstrap broker it connects to. 
The Kafka RPCs are individually versioned, so in order to send requests that the server will understand, the Apache Kafka clients need to know the versions supported by the server.
The `API_VERSIONS` request allows a client to discover this.
By sending a `API_VERSIONS` request first, a client can determine which versions of all the other RPCs it should use by taking `max(intersection(supported_client_versions, supported_broker_versions))` for that particular API.

2. Possibly to authenticate to the server. The `API_VERSIONS` request is the only one which a listener requiring authentication will handle without requiring authentication of its peer. 
If TLS is used for authentication then the server will already know the client's identity as a result of the TLS handshake. 
If SASL is being used then `SASL_HANDSHAKE` and `SASL_AUTHENTICATE` are exchanged.

3. To discover information about the cluster, including the currently live brokers and information about certain topics of interest to the client.
This is done using `METADATA` requests.
One response with the information about the live brokers is enough to bootstrap the client, but clients typically make more later as the state of the client and cluster changes. 

The process described above is common to all _Apache_ Kafka clients.
Other client libraries sometimes work slightly differently.
For example, a Sarama client has to be configured with the version of the broker it is talking to and uses a hard-coded mapping from "broker version" to supported API versions. 

In the following sections we'll explore these requests in detail.

## `API_VERSIONS`

### `ApiVersionsRequest`

The API_VERSIONS request is trivial, having only a couple of optional fields for telling the server the name and version of the client library.
// TODO for each request: required authz, idempotency
[id=ApiVersionsRequest]
[source,javascript]
.The API_VERSIONS request
----
include::../kafka-sources/clients/src/main/resources/common/message/ApiVersionsRequest.json[lines=16..-1]
----

### `ApiVersionsResponse`

The response is essentially composed of a object for each API/RPC key, containing the maximum and minimum version supported by the broker. 
[id=ApiVersionsResponse]
[source,javascript]
.The API_VERSIONS response
----
include::../kafka-sources/clients/src/main/resources/common/message/ApiVersionsResponse.json[lines=16..-1]
----

// client doesn't know broker version
NOTE:: The API versions response does not include a server software version, e.g. that a broker is running Kafka 3.0. 
This is intentional as it discourages clients from becoming dependent on the broker version (e.g. using it to work around bugs).
The rationale is that it's better that the broker be fixed by a software update than for clients implement version-specific behaviour.
Of course this does not prevent the set of RPCs and their maximum and minimum versions being used to infer the broker version.

// Feature gates
KIP-584 added support for 'feature gates', which is a mechanism for versioning features which apply at the cluster level (rather than per-broker API versioning).
The supported and enabled features are also included.
Features are only supported when all servers in a cluster support them, and are enabled by an administrator.

## SASL authentication (`SASL_HANDSHAKE` and `SASL_AUTHENTICATE`)

KIP-12 added support for SASL/GSSAPI (aka Kerberos v5) and SSL/TLS. These are both negotiated in the transport layer, and so there's no need for application-level APIs for them.

### `SaslHandshakeRequest` 

The request nominates a SASL mechanism

[id=SaslHandshakeRequest]
[source,javascript]
.The `SASL_HANDSHAKE` request
----
include::../kafka-sources/clients/src/main/resources/common/message/SaslHandshakeRequest.json[lines=16..-1]
----

### `SaslHandshakeResponse` 

The response either rejects the request (`UNSUPPORTED_SASL_MECHANISM`) with a list of the supported mechanisms, or agrees to the selected mechanism.

[id=SaslHandshakeResponse]
[source,javascript]
.The `SASL_HANDSHAKE` response
----
include::../kafka-sources/clients/src/main/resources/common/message/SaslHandshakeResponse.json[lines=16..-1]
----

What happens next depends on the support broker and client versions.

For `SASL_HANDSHAKE` version 0 (defined in KIP-43), on receipt of the response the client stops sending normal Kafka-framed RPCs and starts a SASL exchange over the connection, serialized as a simple Kafka array without any message header.
Once this exchange has completed (and resulted in success) Kafka RPCs can again be sent.

[source]
.Example v0 SASL/Plain conversation (adapted from RFC-4616) showing framing/encapsulation
----
C(Kafka): SaslHandShake(mechanism=plain)  <1>
S(Kafka): SaslHandshake(error=0)          <2>
C(SASL): <NUL>tim<NUL>tanstaaftanstaaf    <3>
S(SASL): // return an empty SASL frame    <4>
... further Kafka frames
----
<1> I want to use Plain
<2> OK, use plain
<3> I'm tim, my password is tanstaaftanstaaf
<4> I agree, you are

While this works for SASL/Plain there is no mechanism-independent way for a server to tell a client the exchange has failed.
This makes it hard for clients to handle failed exchanges.

### `SaslAuthenticateRequest` 

For version `SASL_HANDSHAKE` 1+ (defined by KIP-152) the SASL exchange is wrapped in Kafka-level `SASL_AUTHENTICATE` requests and responses

[source]
.Example v1 SASL/Plain conversation (adapted from RFC-4616) showing Kafka framing
----
C(Kafka): SaslHandshake(mechanism=plain)
S(Kafka): SaslHandshake(error=0)
C(Kafka): SaslAuthenticate(sasl_auth_bytes=<NUL>tim<NUL>tanstaaftanstaaf) <1>
S(Kafka): SaslAuthenticate(error_code=0, sasl_auth_bytes=) // empty       <2>
... further Kafka frames
----
<1> Encapsulated in a Kafka request
<2> Encapsulated in a Kafka response

[id=SaslAuthenticateRequest]
[source,javascript]
.The `SASL_AUTHENTICATE` request
----
include::../kafka-sources/clients/src/main/resources/common/message/SaslAuthenticateRequest.json[lines=16..-1]
----

### `SaslAuthenticateResponse` 

[id=SaslAuthenticateResponse]
[source,javascript]
.The `SASL_AUTHENTICATE` response
----
include::../kafka-sources/clients/src/main/resources/common/message/SaslAuthenticateResponse.json[lines=16..-1]
----

Support for SASL/SCRAM (KIP-84) and SASL/OAUTHBEARER (KIP-255) works in the same way, though SCRAM requires multiple `SASL_AUTHENTICATE` exchanges.


// TODO example logging of successful and failed SASL authentication

## Metadata requests

// The initial cluster request
The minimum information needed to bootstrap a client is the set of live brokers and how they can be connected to.
The client obtains this using a `METADATA` request to a bootstrap broker (having first found out its supported API versions and authenticated to it).

### `MetadataRequest`

[id=MetadataRequest]
[source,javascript]
.The `METADATA` request
----
include::../kafka-sources/clients/src/main/resources/common/message/MetadataRequest.json[lines=16..-1]
----

// TODO example log for a bootstrap metadata request (explain the negative broker ids)

// Topic requests
Information about some (possibly empty) set of topics can be requested at the same time. 
// Topic creation by side-effect
The possibility of creating topics as a side-effect means that metadata requests are not idempotent, and is not good protocol design.
Support for this was added before the Admin client was a viable alternative for creating topics explicitly.
// authorized operations
Support for obtaining information about what the authenticated principal can do was also an ad-doc addition to the API to support the Admin client. 

// Refreshing metadata
The Apache Kafka clients have a cache of the metadata and will refresh it when:

* they observe a response which an error code which implies that the metadata is out of date
* periodically, if it's not otherwise been refreshed

The producer and consumer metadata handling is entirely managed in this way and hence is hidden from the user. 
In the admin client, the user visible methods such as `describeCluster()`, `listTopics()` and `describeTopics()` will always send a metadata request, rather than serving possibly stale data from the cache. 
The cache itself is not updated by these explicit requests either: The two paths for metadata requests are completely independent. 

### `MetadataResponse`

[id=MetadataResponse]
[source,javascript]
.The `METADATA` response
----
include::../kafka-sources/clients/src/main/resources/common/message/MetadataResponse.json[lines=16..-1]
----

The cluster is described by the _live_ brokers in the `Brokers` array.
No information about non-live brokers is included, even though their existence may be inferred from other parts of the response (e.g. `Topics/Partitions/ReplicaNodes`.

When a partition doesn't have a leader its `LeaderId` will be -1.

// TODO example logging for a the bootstrap metadata response

// TODO Metadata in the admin client (CLUSTER_METADATA)

## Summary

A "typical" client bootstrapping exchange looks like this:
[source]
.Typical successful client bootstrapping
----
C: ApiVersions v3
S: ApiVersions v3 (ErrorCode=0,
                   ApiKeys=[{ApiKey=SaslHandshake, Min=0, Max=1},
                            {ApiKey=SaslAuthenticate, Min=0, Max=2},
                            {ApiKey=Metadata, Min=0, Max=11}, ...])
C: SaslHandshake v1 (Mechanism=plain)
S: SaslHandshake v1 (ErrorCode=0)
C: SaslAuthenticate v2 (sasl_auth_bytes=<NUL>tim<NUL>tanstaaftanstaaf)
S: SaslAuthenticate v2 (ErrorCode=0, sasl_auth_bytes=) // empty
C: Metadata v11 ()
S: Metadata v11 (ErrorCode=0, Brokers=...)
----

And whenever a client is disconnected from a broker we'd expect to see the same pattern, minus the metadata request/response.
